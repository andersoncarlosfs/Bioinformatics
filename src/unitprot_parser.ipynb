{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing UnitProt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to generate queries from data\n",
    "\n",
    "The following functions are used in the generation of SQL script from data.\n",
    "\n",
    "**toSQLStr** converts a chunk of data (a tuple/list or a single element) to a format suited for an INSERT query.\n",
    "The main problem encountered here is that some names may contains single quotes('). SQL allows escaping those by adding an additional quote :\n",
    "    'go'el' => 'go''el'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    " def toSQLStr(tup):\n",
    "    result = \"(\"\n",
    "    if type(tup) == str:\n",
    "        subitem = \"\"\n",
    "        for c in tup:\n",
    "            if c in \"'\":\n",
    "                subitem = subitem + \"'\"\n",
    "            subitem = subitem + c\n",
    "        result = result + \"'\" + subitem + \"'\"\n",
    "    elif type(tup) == tuple or type(tup) == list:\n",
    "        first = True\n",
    "        for item in tup:\n",
    "            if first:\n",
    "                first = False\n",
    "            else:\n",
    "                result = result + \", \"\n",
    "            if type(item) == str:\n",
    "                subitem = \"\"\n",
    "                for c in item:\n",
    "                    if c in \"'\":\n",
    "                        subitem = subitem + \"'\"\n",
    "                    subitem = subitem + c\n",
    "                result = result + \"'\" + subitem + \"'\"\n",
    "            else:\n",
    "                result = result + str(item)\n",
    "    return result + \")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**writeInsertQuery** generates an INSERT query from the lines given as parameter. \n",
    "It uses the above function to convert those lines of data to a format suitable to SQL.\n",
    "The query is written to the file specified by `filepath`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeInsertQuery(table, lines, filepath):\n",
    "    if len(lines) == 0 or not table or not filepath:\n",
    "        return\n",
    "    with open(filepath, \"w\") as outf:\n",
    "        outf.write(\"INSERT INTO TABLE \" + table + \" VALUES\")\n",
    "        outf.writelines(\"\\n\" + toSQLStr(line) for line in lines)\n",
    "        outf.write(\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str.split(delimiter) returns also empty elements; this function simply removes them\n",
    "def split(s, delimiter):\n",
    "    content = s.split(delimiter)\n",
    "    return [item for item in content if item]\n",
    "\n",
    "# This function adds an couple key-value to a dict assuming it associates a key to a list.\n",
    "# The value is meant to be added to the array, but if the key does not exist, you will need to create the array first. \n",
    "# This function creates this array for you if it doesn't exist yet.\n",
    "def appendToSubArray(di, key, value):\n",
    "    if not key in di:\n",
    "        di[key] = []\n",
    "    di[key].append(value)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing UnitProt\n",
    "\n",
    "The main dish; parsing the UnitProt file.\n",
    "\n",
    "We are only interested in specific lines, so we extract only those. For every line, we keep it as a tuple `(type of line, content)`. A line is parsed with the '\\n' char at the end, so we take the opportunity to remove it with `[:-1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_lines = []\n",
    "with open(\"../Datasets/UniProtKB/unitprot-cancer/unitprot-cancer.txt\") as cf:\n",
    "    for line in cf:\n",
    "        content = split(line, ' ')\n",
    "        if len(content) > 0 and content[0] in ['ID', 'AC', 'DE', 'GN', 'KW', 'DR']:\n",
    "            cancer_lines.append((content[0], (' '.join(content[1:]))[:-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the UnitProt file, an entry always begins with the line `ID`, where we find the name of entry. To gather the data related to an entry, we use the class `DataEntry` which will contain all of it. Once we encounter a new line `ID`, we create a new data entry, and we store the previous one.\n",
    "\n",
    "Among the other lines that are of interest to us, there is :\n",
    "\n",
    "### Accession numbers (AC)\n",
    "\n",
    "Items are separated by semicolons. Parsing it is pretty straightforward.\n",
    "\n",
    "### Keywords (KW)\n",
    "\n",
    "Items are separated by semicolons. Parsing it is pretty straightforward.\n",
    "\n",
    "### Data cross-reference (DR)\n",
    "\n",
    "This line contains different kinds of data. We are only interested here in the GO (Gene Ontology) numbers. A line that contains a GO number always begins with GO, so we check for that.\n",
    "\n",
    "### Gene names (GN)\n",
    "\n",
    "\n",
    "\n",
    "### Description (DE)\n",
    "\n",
    "This is the most complex line to parse here. The line may have the following formats, for what interests us : \n",
    "\n",
    "    1 <Category>: <subcategory>=<value>\n",
    "    2           <subcategory>=<value>\n",
    "    3 <Supercategory>:\n",
    "    4         <Category>: <subcategory>=<value>\n",
    "    5                  <subcategory>=<value>\n",
    "    6 Flags: <value>\n",
    "\n",
    "There are `.strip()`s here and there to remove whitespace noise. We also try to exclude the semicolons at the end of results with `[:-1]`.\n",
    "\n",
    "We remove the content between brackets, as we do not take it into account, by splitting the line by '{' and keeping only the left element.\n",
    "\n",
    "You can see the details on the data these lines contain [here](https://web.expasy.org/docs/userman.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataEntry:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.ac = []\n",
    "        self.desc = {\"AltName\" : {}, \n",
    "                     \"RecName\" : {},\n",
    "                     \"SubName\" : {},\n",
    "                     \"Contains\" : {\n",
    "                         \"RecName\" : {}, \n",
    "                         \"AltName\" : {}, \n",
    "                         \"SubName\" : {}\n",
    "                     }, \n",
    "                     \"Includes\" : {\n",
    "                         \"RecName\" : {}, \n",
    "                         \"AltName\" : {}, \n",
    "                         \"SubName\" : {}\n",
    "                     }\n",
    "                    }\n",
    "        self.flags = []\n",
    "        self.go = []\n",
    "        self.keywords = []\n",
    "        self.gn = {}\n",
    "        \n",
    "    # Generates triples from the data. Not updated.\n",
    "    def triples(self):\n",
    "        triples = []\n",
    "        \n",
    "        # Keywords\n",
    "        for item in self.keywords:\n",
    "            triples.append((self.id, \"keyword\", item))\n",
    "            \n",
    "        # Accession numbers\n",
    "        for item in self.ac:\n",
    "            triples.append((self.id, \"acnumber\", item))\n",
    "            \n",
    "        # Recommended Names\n",
    "        if 'RecName' in self.desc:\n",
    "            for item in self.desc['RecName']:\n",
    "                triples.append((self.id, \"recname\", item))\n",
    "        \n",
    "        # Alternative Names\n",
    "        if 'AltName' in self.desc:\n",
    "            for item in self.desc['AltName']:\n",
    "                triples.append((self.id, \"altname\", item))\n",
    "            \n",
    "        return triples\n",
    "    \n",
    "    # Translates the data to a printable format.\n",
    "    def __str__(self):\n",
    "        desc = \"\"\n",
    "        desc = desc + \"ID=\" + self.id \n",
    "        desc = desc +\"\\nDescription=\" + str(self.desc)\n",
    "        desc = desc + \"\\nKeywords=\" + str(self.keywords)\n",
    "        desc = desc + \"\\nACcessionNumbers=\" + str(self.ac)\n",
    "        desc = desc + \"\\nGeneNames=\" + str(self.gn)\n",
    "        desc = desc + \"\\nGeneOntology=\" + str(self.go)\n",
    "        return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cancerData = []\n",
    "\n",
    "# Loop external data\n",
    "\n",
    "# The current data entry\n",
    "currentEntry = None\n",
    "\n",
    "# Those two corresponds to the keys that have been declared \n",
    "# previously in the DataEntry class desc field, category\n",
    "# being at the first level and subCategory the second level.\n",
    "\n",
    "# Expected values : [Contains, Includes, None]\n",
    "subCategory = None\n",
    "\n",
    "# Expected values : [AltName, RecName, SubName]\n",
    "category = None\n",
    "            \n",
    "for line in cancer_lines:\n",
    "    \n",
    "    # If the line is empty, continue on to the next iteration\n",
    "    if not line[1]:\n",
    "        continue\n",
    "    \n",
    "    # If we encounter an ID line\n",
    "    if (line[0] == 'ID'):\n",
    "        # We create a new data entry and store it.\n",
    "        # All following lines will store their data into this entry, until we meet a new ID line.\n",
    "        currentEntry = DataEntry(line[1].split(' ')[0])\n",
    "        cancerData.append(currentEntry)\n",
    "\n",
    "    elif (line[0] == 'AC'):\n",
    "        if currentEntry:\n",
    "                [currentEntry.ac.append(item.strip()) for item in split(line[1], ';')]\n",
    "                \n",
    "    elif (line[0] == 'KW'):\n",
    "        if currentEntry:\n",
    "                [currentEntry.keywords.append(item.strip()) for item in split(line[1], ';')]\n",
    "                \n",
    "    elif (line[0] == 'DR'):\n",
    "        if currentEntry:\n",
    "                semicolonsplit = split(line[1], ';')\n",
    "                # check if the line begins with 'GO', in which case we retrieve the GO number in the line\n",
    "                if len(semicolonsplit) > 1 and semicolonsplit[0] == 'GO':\n",
    "                    currentEntry.go.append(split(semicolonsplit[1], ':')[1].strip())     \n",
    "    \n",
    "    elif (line[0] == 'GN'):\n",
    "        \n",
    "        if currentEntry:\n",
    "            \n",
    "            # we ignore the lines that only contains 'and'\n",
    "            if line[1] == 'and':\n",
    "                continue\n",
    "                \n",
    "            # Gene names are separated by semicolons.\n",
    "            # An item is of the form <category>=<value>[, <value2>, ...].\n",
    "            for item in split(line[1], ';'):\n",
    "                \n",
    "                content = split(item, '=')\n",
    "                \n",
    "                if len(content) > 1:\n",
    "                    # there may be several values, separated by commas\n",
    "                    commasplit = split(content[1], ',')\n",
    "                    for item in commasplit:\n",
    "                        value = split(item, '{')[0].strip()\n",
    "                        # we store the value in the array of category\n",
    "                        appendToSubArray(currentEntry.gn, content[0].strip(), value)\n",
    "                    \n",
    "    elif (line[0] == 'DE'):\n",
    "        if currentEntry:\n",
    "            colonsplit = split(line[1], ':')\n",
    "            if len(colonsplit) and colonsplit[0] in ['Contains', 'Includes']:\n",
    "                category = colonsplit[0]\n",
    "            elif len(colonsplit) and colonsplit[0] in ['AltName', 'RecName', 'SubName']:\n",
    "                subCategory = colonsplit[0]\n",
    "                content = split(colonsplit[1][:-1], '=')\n",
    "                \n",
    "                # to remove the content between brackets\n",
    "                value = split(content[1], '{')[0].strip()\n",
    "                if category:\n",
    "                    appendToSubArray(currentEntry.desc[category][subCategory], content[0].strip(), value)\n",
    "                else:\n",
    "                    appendToSubArray(currentEntry.desc[subCategory], content[0].strip(), value)\n",
    "            elif colonsplit[0] == 'Flags':\n",
    "                currentEntry.flags.append(colonsplit[1][:-1].strip())\n",
    "            else:\n",
    "                content = split(line[1], '=')\n",
    "                if len(content) < 2:\n",
    "                    continue\n",
    "                # to remove the content between brackets\n",
    "                value = split(content[1][:-1], '{')[0].strip()\n",
    "                if category and subCategory:\n",
    "                    appendToSubArray(currentEntry.desc[category][subCategory], content[0].strip(), value)\n",
    "                elif subCategory:\n",
    "                    appendToSubArray(currentEntry.desc[subCategory], content[0].strip(), value)\n",
    "                \n",
    "    \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content of a data entry\n",
    "\n",
    "Once we have extracted the UnitProt entries, we can preview what data one such entry holds, from what we have parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID=P53_HUMAN\n",
      "Description={'AltName': {'Full': ['Antigen NY-CO-13', 'Phosphoprotein p53', 'Tumor suppressor p53']}, 'Includes': {'AltName': {}, 'RecName': {}, 'SubName': {}}, 'Contains': {'AltName': {}, 'RecName': {}, 'SubName': {}}, 'RecName': {'Full': ['Cellular tumor antigen p53']}, 'SubName': {}}\n",
      "Keywords=['3D-structure', 'Acetylation', 'Activator', 'Alternative promoter usage', 'Alternative splicing', 'Apoptosis', 'Biological rhythms', 'Cell cycle', 'Complete proteome', 'Cytoplasm', 'Disease mutation', 'DNA-binding', 'Endoplasmic reticulum', 'Glycoprotein', 'Host-virus interaction', 'Isopeptide bond', 'Li-Fraumeni syndrome', 'Metal-binding', 'Methylation', 'Mitochondrion', 'Necrosis', 'Nucleus', 'Phosphoprotein', 'Polymorphism', 'Reference proteome', 'Repressor', 'Transcription', 'Transcription regulation', 'Tumor suppressor', 'Ubl conjugation', 'Zinc.']\n",
      "ACcessionNumbers=['P04637', 'Q15086', 'Q15087', 'Q15088', 'Q16535', 'Q16807', 'Q16808', 'Q16809', 'Q16810', 'Q16811', 'Q16848', 'Q2XN98', 'Q3LRW1', 'Q3LRW2', 'Q3LRW3', 'Q3LRW4', 'Q3LRW5', 'Q86UG1', 'Q8J016', 'Q99659', 'Q9BTM4', 'Q9HAQ8', 'Q9NP68', 'Q9NPJ2', 'Q9NZD0', 'Q9UBI2', 'Q9UQ61']\n",
      "GeneNames={'Synonyms': ['P53'], 'Name': ['TP53']}\n",
      "GeneOntology=['0005737', '0005829', '0005783', '0005622', '0005759', '0005739', '0000790', '0016363', '0005730', '0005654', '0005634', '0016605', '0043234', '0005657', '0005524', '0051087', '0003682', '0005507', '0001046', '0003684', '0097718', '0003677', '0019899', '0035035', '0042826', '0042802', '0003730', '0002039', '0002020', '0046982', '0019901', '0047485', '0051721', '0019903', '0043621', '0030971', '0000977', '0000981', '0001085', '0000990', '0003700', '0008134', '0044212', '0001228', '0031625', '0008270', '0006914', '0006284', '0007569', '0007050', '0030154', '0008283', '0034613', '0072717', '0006974', '0035690', '0071480', '0042149', '0071456', '0071479', '0034644', '0031497', '0048512', '0008340', '0030330', '0006977', '0006978', '0000733', '0043153', '0006983', '0097193', '0072332', '0042771', '0031571', '0009299', '0007275', '0043066', '0030308', '0008285', '0048147', '0051097', '0051974', '0000122', '0045892', '0006289', '0097252', '0090403', '0043065', '0071158', '1900119', '0010628', '0031065', '2001244', '0043525', '0050731', '1902895', '0046827', '1900740', '0032461', '2000379', '0090200', '0070245', '0045944', '1990440', '0045893', '0043161', '0006461', '0016579', '0051289', '0008104', '0051262', '0007265', '0042981', '1902749', '0046902', '1901796', '0006355', '0090399', '0046677', '0010332', '0010165', '0072331', '0016032']\n"
     ]
    }
   ],
   "source": [
    "if len(cancerData):\n",
    "    print(cancerData[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating queries from data entries\n",
    "\n",
    "Now that we have parsed the data and categorized it, we can start to generate queries to insert the data in a database. Here are the tables we have chosen to hold the data of UnitProt :\n",
    "\n",
    "### The ID table\n",
    "\n",
    "This table contains only the id (1) of every entry.\n",
    "\n",
    "### The AC table\n",
    "\n",
    "For every accession number of an entry, it contains :\n",
    "* the entry id (1);\n",
    "* and an associated accession number (2).\n",
    "\n",
    "### The KW table\n",
    "\n",
    "For every keyword of an entry, it contains : \n",
    "* the entry id (1) \n",
    "* the associated keyword (2).\n",
    "\n",
    "### The GeneName table\n",
    "\n",
    "For every gene name of an entry, it contains :\n",
    "* the entry id (1) \n",
    "* the type of name (2) \n",
    "* the gene name (3).\n",
    "\n",
    "The type can take three values : \n",
    "* synonym\n",
    "* orfname\n",
    "* name\n",
    "\n",
    "### The Gene Ontology table\n",
    "\n",
    "For every gene ontology reference of an entry, it contains :\n",
    "* the entry id (1) \n",
    "* the reference number (2).\n",
    "\n",
    "### The Flag table\n",
    "\n",
    "For every flag of an entry, it contains :\n",
    "* the entry id (1) \n",
    "* the flag (2).\n",
    "\n",
    "### The Name table\n",
    "\n",
    "This table bundles the description data into one table. It contains :\n",
    "* the entry id\n",
    "* the name category (AltName, RecName, SubName)\n",
    "* the name subcategory (Full, Short, EC)\n",
    "* the actual name\n",
    "\n",
    "You can alter the names of the tables in the query below if you so wish.\n",
    "\n",
    "The code below generate one SQL script for each table.\n",
    "\n",
    "You can find the database schema [here](../Database/unitprot_database.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change your table names here\n",
    "id_table = \"unitprot\"\n",
    "ac_table = \"accession_number_unitprot\"\n",
    "name_table = \"description_unitprot\"\n",
    "keyword_table = \"keyword_unitprot\"\n",
    "genename_table = \"gene_name_unitprot\"\n",
    "gene_ontology_table = \"go_unitprot\"\n",
    "flag_table = \"flag_unitprot\"\n",
    "\n",
    "lines = {\n",
    "    id_table : [],\n",
    "    ac_table : [], \n",
    "    # if you want to have both altname and recname in the same table, use this one\n",
    "    name_table: [],\n",
    "    keyword_table : [], \n",
    "    genename_table : [], \n",
    "    gene_ontology_table : [],\n",
    "    flag_table : []}\n",
    "\n",
    "for entry in cancerData:\n",
    "    \n",
    "    # id table\n",
    "    lines[id_table].append((entry.id))\n",
    "    \n",
    "    # ac table\n",
    "    [lines[ac_table].append((entry.id, item)) for item in entry.ac]\n",
    "    \n",
    "    # Name table\n",
    "    # alternative names\n",
    "    [lines[name_table].append((entry.id, \"AltName\", k, item)) for k, names in entry.desc[\"AltName\"].items() for item in names]\n",
    "    [lines[name_table].append((entry.id, \"AltName\", k, item)) for k, names in entry.desc[\"Contains\"][\"AltName\"].items() for item in names]\n",
    "    [lines[name_table].append((entry.id, \"AltName\", k, item)) for k, names in entry.desc[\"Includes\"][\"AltName\"].items() for item in names]\n",
    "    \n",
    "    # recommended names\n",
    "    [lines[name_table].append((entry.id, \"RecName\", k, item)) for k, names in entry.desc[\"RecName\"].items() for item in names]\n",
    "    [lines[name_table].append((entry.id, \"RecName\", k, item)) for k, names in entry.desc[\"Contains\"][\"RecName\"].items() for item in names]\n",
    "    [lines[name_table].append((entry.id, \"RecName\", k, item)) for k, names in entry.desc[\"Includes\"][\"RecName\"].items() for item in names]\n",
    "    \n",
    "    # flag table\n",
    "    [lines[flag_table].append((entry.id, item)) for item in entry.flags]\n",
    "    \n",
    "    # keyword table\n",
    "    [lines[keyword_table].append((entry.id, item)) for item in entry.keywords]\n",
    "    \n",
    "    # gene ontology table\n",
    "    [lines[gene_ontology_table].append((entry.id, item)) for item in entry.go]\n",
    "    \n",
    "    # gene name table\n",
    "    [lines[genename_table].append((entry.id, k if \"s\" not in k else k[:-1], item)) for k, v in entry.gn.items() for item in v]\n",
    "    \n",
    "for key, value in lines.items():\n",
    "    writeInsertQuery(key, value, \"queries/\" + str(key) + \".sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the end of the notebook !\n"
     ]
    }
   ],
   "source": [
    "print(\"Reached the end of the notebook !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
