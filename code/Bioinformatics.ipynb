{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to describe the extract, transform, load (ETL) process for gene-specific data from NCBI and UniProt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook works with Python 2.7.14. However, some external libraries are necessary to be include in the python enviroment if not yet done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# uncompressing files\n",
    "def _uncompress(_path):\n",
    "    with gzip.open(_path, 'rb') as _input, open('./' + os.path.splitext(os.path.basename(_path))[0], 'w') as _output:\n",
    "        # moving and renaming files\n",
    "        shutil.copyfileobj(_input, _output) \n",
    "        return os.path.basename(_output.name)\n",
    "    \n",
    "# reading files    \n",
    "def _read(_path):\n",
    "    return pandas.read_csv(_path, delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section describe the datasets used in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_datasets = '../datasets/'\n",
    "\n",
    "_datasets = {\n",
    "    'Homo_sapiens.gene_info': _datasets + 'NCBI/Homo_sapiens.gene_info.gz',\n",
    "    'gene2go': _datasets + 'NCBI/gene2go.gz',\n",
    "    'UniProtKB': _datasets + 'UniProt/uniprot-cancer+AND+reviewed%3Ayes+AND+organism%3A%22Homo+sapiens+%28Human%29+%5B--.txt.gz'\n",
    "}\n",
    "\n",
    "# uncompressing files\n",
    "for _index in _datasets:\n",
    "    _datasets[_index] = _uncompress(_datasets[_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homo_sapiens.gene_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset = _read(_datasets['Homo_sapiens.gene_info'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows a sample of the contents of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#tax_id</th>\n",
       "      <th>GeneID</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>LocusTag</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>dbXrefs</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>map_location</th>\n",
       "      <th>description</th>\n",
       "      <th>type_of_gene</th>\n",
       "      <th>Symbol_from_nomenclature_authority</th>\n",
       "      <th>Full_name_from_nomenclature_authority</th>\n",
       "      <th>Nomenclature_status</th>\n",
       "      <th>Other_designations</th>\n",
       "      <th>Modification_date</th>\n",
       "      <th>Feature_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9606</td>\n",
       "      <td>1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>-</td>\n",
       "      <td>A1B|ABG|GAB|HYST2477</td>\n",
       "      <td>MIM:138670|HGNC:HGNC:5|Ensembl:ENSG00000121410...</td>\n",
       "      <td>19</td>\n",
       "      <td>19q13.43</td>\n",
       "      <td>alpha-1-B glycoprotein</td>\n",
       "      <td>protein-coding</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>alpha-1-B glycoprotein</td>\n",
       "      <td>O</td>\n",
       "      <td>alpha-1B-glycoprotein|HEL-S-163pA|epididymis s...</td>\n",
       "      <td>20171221</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9606</td>\n",
       "      <td>2</td>\n",
       "      <td>A2M</td>\n",
       "      <td>-</td>\n",
       "      <td>A2MD|CPAMD5|FWP007|S863-7</td>\n",
       "      <td>MIM:103950|HGNC:HGNC:7|Ensembl:ENSG00000175899...</td>\n",
       "      <td>12</td>\n",
       "      <td>12p13.31</td>\n",
       "      <td>alpha-2-macroglobulin</td>\n",
       "      <td>protein-coding</td>\n",
       "      <td>A2M</td>\n",
       "      <td>alpha-2-macroglobulin</td>\n",
       "      <td>O</td>\n",
       "      <td>alpha-2-macroglobulin|C3 and PZP-like alpha-2-...</td>\n",
       "      <td>20171223</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9606</td>\n",
       "      <td>3</td>\n",
       "      <td>A2MP1</td>\n",
       "      <td>-</td>\n",
       "      <td>A2MP</td>\n",
       "      <td>HGNC:HGNC:8|Ensembl:ENSG00000256069</td>\n",
       "      <td>12</td>\n",
       "      <td>12p13.31</td>\n",
       "      <td>alpha-2-macroglobulin pseudogene 1</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>A2MP1</td>\n",
       "      <td>alpha-2-macroglobulin pseudogene 1</td>\n",
       "      <td>O</td>\n",
       "      <td>pregnancy-zone protein pseudogene</td>\n",
       "      <td>20170903</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9606</td>\n",
       "      <td>9</td>\n",
       "      <td>NAT1</td>\n",
       "      <td>-</td>\n",
       "      <td>AAC1|MNAT|NAT-1|NATI</td>\n",
       "      <td>MIM:108345|HGNC:HGNC:7645|Ensembl:ENSG00000171...</td>\n",
       "      <td>8</td>\n",
       "      <td>8p22</td>\n",
       "      <td>N-acetyltransferase 1</td>\n",
       "      <td>protein-coding</td>\n",
       "      <td>NAT1</td>\n",
       "      <td>N-acetyltransferase 1</td>\n",
       "      <td>O</td>\n",
       "      <td>arylamine N-acetyltransferase 1|N-acetyltransf...</td>\n",
       "      <td>20171105</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9606</td>\n",
       "      <td>10</td>\n",
       "      <td>NAT2</td>\n",
       "      <td>-</td>\n",
       "      <td>AAC2|NAT-2|PNAT</td>\n",
       "      <td>MIM:612182|HGNC:HGNC:7646|Ensembl:ENSG00000156...</td>\n",
       "      <td>8</td>\n",
       "      <td>8p22</td>\n",
       "      <td>N-acetyltransferase 2</td>\n",
       "      <td>protein-coding</td>\n",
       "      <td>NAT2</td>\n",
       "      <td>N-acetyltransferase 2</td>\n",
       "      <td>O</td>\n",
       "      <td>arylamine N-acetyltransferase 2|N-acetyltransf...</td>\n",
       "      <td>20171217</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #tax_id  GeneID Symbol LocusTag                   Synonyms  \\\n",
       "0     9606       1   A1BG        -       A1B|ABG|GAB|HYST2477   \n",
       "1     9606       2    A2M        -  A2MD|CPAMD5|FWP007|S863-7   \n",
       "2     9606       3  A2MP1        -                       A2MP   \n",
       "3     9606       9   NAT1        -       AAC1|MNAT|NAT-1|NATI   \n",
       "4     9606      10   NAT2        -            AAC2|NAT-2|PNAT   \n",
       "\n",
       "                                             dbXrefs chromosome map_location  \\\n",
       "0  MIM:138670|HGNC:HGNC:5|Ensembl:ENSG00000121410...         19     19q13.43   \n",
       "1  MIM:103950|HGNC:HGNC:7|Ensembl:ENSG00000175899...         12     12p13.31   \n",
       "2                HGNC:HGNC:8|Ensembl:ENSG00000256069         12     12p13.31   \n",
       "3  MIM:108345|HGNC:HGNC:7645|Ensembl:ENSG00000171...          8         8p22   \n",
       "4  MIM:612182|HGNC:HGNC:7646|Ensembl:ENSG00000156...          8         8p22   \n",
       "\n",
       "                          description    type_of_gene  \\\n",
       "0              alpha-1-B glycoprotein  protein-coding   \n",
       "1               alpha-2-macroglobulin  protein-coding   \n",
       "2  alpha-2-macroglobulin pseudogene 1          pseudo   \n",
       "3               N-acetyltransferase 1  protein-coding   \n",
       "4               N-acetyltransferase 2  protein-coding   \n",
       "\n",
       "  Symbol_from_nomenclature_authority Full_name_from_nomenclature_authority  \\\n",
       "0                               A1BG                alpha-1-B glycoprotein   \n",
       "1                                A2M                 alpha-2-macroglobulin   \n",
       "2                              A2MP1    alpha-2-macroglobulin pseudogene 1   \n",
       "3                               NAT1                 N-acetyltransferase 1   \n",
       "4                               NAT2                 N-acetyltransferase 2   \n",
       "\n",
       "  Nomenclature_status                                 Other_designations  \\\n",
       "0                   O  alpha-1B-glycoprotein|HEL-S-163pA|epididymis s...   \n",
       "1                   O  alpha-2-macroglobulin|C3 and PZP-like alpha-2-...   \n",
       "2                   O                  pregnancy-zone protein pseudogene   \n",
       "3                   O  arylamine N-acetyltransferase 1|N-acetyltransf...   \n",
       "4                   O  arylamine N-acetyltransferase 2|N-acetyltransf...   \n",
       "\n",
       "   Modification_date Feature_type  \n",
       "0           20171221            -  \n",
       "1           20171223            -  \n",
       "2           20170903            -  \n",
       "3           20171105            -  \n",
       "4           20171217            -  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gene2go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset = _read(_datasets['gene2go'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows a sample of the contents of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#tax_id</th>\n",
       "      <th>GeneID</th>\n",
       "      <th>GO_ID</th>\n",
       "      <th>Evidence</th>\n",
       "      <th>Qualifier</th>\n",
       "      <th>GO_term</th>\n",
       "      <th>PubMed</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3702</td>\n",
       "      <td>814629</td>\n",
       "      <td>GO:0005634</td>\n",
       "      <td>ISM</td>\n",
       "      <td>-</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>-</td>\n",
       "      <td>Component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3702</td>\n",
       "      <td>814629</td>\n",
       "      <td>GO:0008150</td>\n",
       "      <td>ND</td>\n",
       "      <td>-</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>-</td>\n",
       "      <td>Process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3702</td>\n",
       "      <td>814630</td>\n",
       "      <td>GO:0003677</td>\n",
       "      <td>IEA</td>\n",
       "      <td>-</td>\n",
       "      <td>DNA binding</td>\n",
       "      <td>-</td>\n",
       "      <td>Function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3702</td>\n",
       "      <td>814630</td>\n",
       "      <td>GO:0003700</td>\n",
       "      <td>ISS</td>\n",
       "      <td>-</td>\n",
       "      <td>DNA binding transcription factor activity</td>\n",
       "      <td>11118137</td>\n",
       "      <td>Function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3702</td>\n",
       "      <td>814630</td>\n",
       "      <td>GO:0005634</td>\n",
       "      <td>IEA</td>\n",
       "      <td>-</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>-</td>\n",
       "      <td>Component</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #tax_id  GeneID       GO_ID Evidence Qualifier  \\\n",
       "0     3702  814629  GO:0005634      ISM         -   \n",
       "1     3702  814629  GO:0008150       ND         -   \n",
       "2     3702  814630  GO:0003677      IEA         -   \n",
       "3     3702  814630  GO:0003700      ISS         -   \n",
       "4     3702  814630  GO:0005634      IEA         -   \n",
       "\n",
       "                                     GO_term    PubMed   Category  \n",
       "0                                    nucleus         -  Component  \n",
       "1                         biological_process         -    Process  \n",
       "2                                DNA binding         -   Function  \n",
       "3  DNA binding transcription factor activity  11118137   Function  \n",
       "4                                    nucleus         -  Component  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target taxonomy of this project is the Homo sapiens (Human) that holds the taxon indentifier 9606."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_taxon = 9606"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UniProt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UniProtKB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset = _read(_datasets['UniProtKB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows a sample of the contents of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID   P53_HUMAN               Reviewed;         393 AA.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC   P04637; Q15086; Q15087; Q15088; Q16535; Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AC   Q16810; Q16811; Q16848; Q2XN98; Q3LRW1; Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AC   Q3LRW5; Q86UG1; Q8J016; Q99659; Q9BTM4; Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AC   Q9NZD0; Q9UBI2; Q9UQ61;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT   13-AUG-1987, integrated into UniProtKB/Sw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID   P53_HUMAN               Reviewed;         393 AA.\n",
       "0  AC   P04637; Q15086; Q15087; Q15088; Q16535; Q...    \n",
       "1  AC   Q16810; Q16811; Q16848; Q2XN98; Q3LRW1; Q...    \n",
       "2  AC   Q3LRW5; Q86UG1; Q8J016; Q99659; Q9BTM4; Q...    \n",
       "3                       AC   Q9NZD0; Q9UBI2; Q9UQ61;    \n",
       "4  DT   13-AUG-1987, integrated into UniProtKB/Sw...    "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database schema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image below describe the schema of the target database:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Database schema](../database/database.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration file\n",
    "_configuration = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'bioinformatics',\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres'\n",
    "}\n",
    "\n",
    "with open('database.ini', 'w') as _output:\n",
    "    _output.write('[postgresql]' + '\\n')\n",
    "    # writing configuration file\n",
    "    for _parameter in _configuration:\n",
    "        _output.write(_parameter + '=' + _configuration[_parameter] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import itertools\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# converting any value to a string insertable into PostgreSQL\n",
    "def _convert(_data):\n",
    "    if isinstance(_data, int):\n",
    "        return str(_data)\n",
    "    if isinstance(_data, datetime):\n",
    "        # converting a date value to a string insertable into PostgreSQL\n",
    "        return '\\'' + datetime.strftime(_data, \"%Y-%m-%d\") + '\\''\n",
    "    return '\\'' + _data.strip().replace('\\'', '\\'\\'') + '\\''\n",
    "\n",
    "# skipping useless lines\n",
    "def _skip(_line, _fields):\n",
    "    _line = _line.strip()\n",
    "    # skipping comments\n",
    "    if _line.startswith('#'):\n",
    "        return None\n",
    "    # skipping comments  \n",
    "    _parts = _line.split('\\t')\n",
    "    # skipping lines with bad formatation\n",
    "    if len(_parts) != len(_fields):\n",
    "        return None\n",
    "    # skipping lines does not satisfy conditions\n",
    "    if not _parts[0].startswith(str(_taxon)): \n",
    "        return None\n",
    "    return _parts\n",
    "\n",
    "# replacing values under specific conditions\n",
    "def _replace(_text, _data = None):\n",
    "    _text.strip()\n",
    "    # applying user-provided function to values\n",
    "    if isinstance(_data, tuple):\n",
    "        _text = _data[0](_text, _data[1])\n",
    "    # expading value to a list of values\n",
    "    if isinstance(_data, list):\n",
    "        for _part in _text.split('|'):\n",
    "            _data.append(_replace(_part))\n",
    "        return _data\n",
    "    # providing meaning for null values\n",
    "    if _text == '-':\n",
    "        _text = 'NOT AVAILABLE'\n",
    "    # converting any value to a string insertable into PostgreSQL\n",
    "    return _convert(_text)\n",
    "\n",
    "# applying functions to lines\n",
    "def _process(_line, _data, _fields):\n",
    "    _parts = _skip(_line, _fields)\n",
    "    # skipping useless lines\n",
    "    if _parts is None:\n",
    "        return None\n",
    "    # replacing values under specific conditions\n",
    "    for _index, _part in enumerate(_parts):\n",
    "        _data[_index] = _replace(_part, _data[_index])\n",
    "    return _data\n",
    "\n",
    "# creating SQL INSERT INTO statements\n",
    "def _strings(_data, _fields, _relation, _prefix):\n",
    "    _lines = []\n",
    "    _line = ''\n",
    "    _arrays = []\n",
    "    for _index, _value in enumerate(_data):\n",
    "        # adding values to new SQL INSERT INTO statements\n",
    "        if isinstance(_value, list):\n",
    "            _arrays.append(_index)\n",
    "        # appending values to SQL INSERT INTO statement\n",
    "        elif isinstance(_value, str):\n",
    "            _line = _line + ', ' + _value\n",
    "        else :\n",
    "            # warning the user about errors in the SQL INSERT INTO statement\n",
    "            _line = '=>' + _fields[_index] + '\\t ERROR (' + type(_value)\n",
    "            _arrays = []\n",
    "            break\n",
    "    _lines.append('INSERT INTO ' + _relation + ' VALUES (' + _line[2:] + ');\\n') \n",
    "    # adding new SQL INSERT INTO statements\n",
    "    for _index in _arrays:\n",
    "        # adding new SQL INSERT INTO statement\n",
    "        for _value in _data[_index]:\n",
    "            _lines.append('INSERT INTO ' + _fields[_index] + ' VALUES (' + _prefix + ', ' + _value + ');\\n') \n",
    "    return _lines\n",
    "\n",
    "# providing consistency to SQL INSERT INTO statements\n",
    "def _consistency(_data, _fields, _relation):\n",
    "    _line = ''\n",
    "    # appending values to SQL INSERT INTO statement\n",
    "    for _value in _data:\n",
    "        _line = _line + ', ' + _value\n",
    "    _line = ') SELECT ' + _line[2:]\n",
    "    for _field in _fields:\n",
    "        _line = ', ' + _field + _line \n",
    "    _line = 'INSERT INTO ' + _relation + ' (' + _line[2:] + ' FROM ' + _relation + ' WHERE NOT (SELECT TRUE FROM ' + _relation + ' WHERE '\n",
    "    # appending clausules to SQL INSERT INTO statement\n",
    "    for _field, _value in zip(_fields, _data):\n",
    "        _line = _line + _field + ' = ' + _value + ' AND '\n",
    "    return _line[:-5] + ' LIMIT 1);\\n'\n",
    "\n",
    "# removing duplicate lines\n",
    "def _deduplicate(_dataset, *_files):\n",
    "    _output, _path = tempfile.mkstemp()\n",
    "    for _file in _files:\n",
    "        with open(_file, 'r') as _input:\n",
    "            for _line, _group in itertools.groupby(sorted(_input)):\n",
    "                os.write(_output, _line)\n",
    "    os.close(_output)\n",
    "    shutil.move(_path, _dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(_datasets['Homo_sapiens.gene_info'], 'r') as _input:\n",
    "    _fact_file, _fact_path = tempfile.mkstemp()\n",
    "    _dimension_file, _dimension_path = tempfile.mkstemp()\n",
    "    _fields = [\n",
    "        'taxonomy_id',\n",
    "        'gene_id',\n",
    "        'symbol',\n",
    "        'locus_tag',\n",
    "        'synonym',\n",
    "        'db_xref',\n",
    "        'chromosome',\n",
    "        'map_location',\n",
    "        'description',\n",
    "        'type_of_gene',\n",
    "        'symbol_from_nomenclature_authority',\n",
    "        'full_name_from_nomenclature_authority',\n",
    "        'nomenclature_status',\n",
    "        'other_designation',\n",
    "        'modification_date',\n",
    "        'feature_type'\n",
    "    ]\n",
    "    for _line in _input:\n",
    "        _data = [\n",
    "            (int, 10),\n",
    "            (int, 10),\n",
    "            None,\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            [], \n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            [],\n",
    "            (datetime.strptime, '%Y%m%d'), \n",
    "            []\n",
    "        ]\n",
    "        # applying functions to lines\n",
    "        _data = _process(_line, _data, _fields)\n",
    "        if _data is None:\n",
    "            continue\n",
    "        _data.insert(0, _data.pop(1)) # gene_id\n",
    "        # creating SQL INSERT INTO statements\n",
    "        _lines = _strings(_data, _fields, 'ncbi', _data[0])\n",
    "        os.write(_fact_file, _lines.pop(0))\n",
    "        # writing SQL statements\n",
    "        for _line in _lines:\n",
    "            os.write(_dimension_file, _line)\n",
    "    os.close(_fact_file)\n",
    "    os.close(_dimension_file)\n",
    "    # removing duplicate lines\n",
    "    _deduplicate(_datasets['Homo_sapiens.gene_info'], _fact_path, _dimension_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(_datasets['gene2go'], 'r') as _input:\n",
    "    _fact_file, _fact_path = tempfile.mkstemp()\n",
    "    _dimension_file, _dimension_path = tempfile.mkstemp()\n",
    "    _fields = [\n",
    "        'taxonomy_id',\n",
    "        'gene_id',\n",
    "        'go_id',\n",
    "        'evidence',\n",
    "        'qualifier',\n",
    "        'go_term',\n",
    "        'pubmed',\n",
    "        'category'\n",
    "    ]\n",
    "    _labels = [\n",
    "        'go_id',\n",
    "        'evidence',\n",
    "        'go_term',\n",
    "        'category'\n",
    "    ]\n",
    "    for _line in _input:\n",
    "        _data = [\n",
    "            None,\n",
    "            (int, 10),\n",
    "            None,\n",
    "            [],\n",
    "            None,\n",
    "            [],\n",
    "            [],\n",
    "            None\n",
    "        ]\n",
    "        # applying functions to lines\n",
    "        _data = _process(_line, _data, _fields)\n",
    "        if _data is None:\n",
    "            continue\n",
    "        _data.pop(0) # 'taxonomy_id'\n",
    "        for _index, _value in enumerate(_data[2]): # 'evidence'\n",
    "            _data[2][_index] = _value + ', ' + _data[3] + ', ' + _replace('-') \n",
    "        _data.pop(3) # 'qualifier'\n",
    "        _data.pop(4) # 'pubmed'\n",
    "        gene_id = _data.pop(0) # 'gene_id'\n",
    "        # creating SQL INSERT INTO statements\n",
    "        _lines = _strings(_data, _labels, 'go', _data[0])\n",
    "        os.write(_fact_file, _lines.pop(0))\n",
    "        # writing SQL statements\n",
    "        for _line in _lines:\n",
    "            os.write(_dimension_file, _line)\n",
    "        # writing SQL statements\n",
    "        for _line in _strings([gene_id, _data[0]], [_fields[1], _labels[0]], 'ncbi_go', None):\n",
    "            os.write(_dimension_file, _line)\n",
    "    os.close(_fact_file)\n",
    "    os.close(_dimension_file)\n",
    "    # removing duplicate lines\n",
    "    _deduplicate(_datasets['gene2go'], _fact_path, _dimension_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-15-de10c3827f1d>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-de10c3827f1d>\"\u001b[0;36m, line \u001b[0;32m39\u001b[0m\n\u001b[0;31m    for _line in _strings([_id, _flag], [_labels[0], '_flag'], 'uniprot', None):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "with open(_datasets['UniProtKB'], 'r') as _input:\n",
    "    _fact_file, _fact_path = tempfile.mkstemp()\n",
    "    _dimension_file, _dimension_path = tempfile.mkstemp()\n",
    "    _fields = [\n",
    "        'ID', \n",
    "        'AC', \n",
    "        'DE', \n",
    "        'GN', \n",
    "        'KW', \n",
    "        'DR',\n",
    "    ]\n",
    "    _labels = [\n",
    "        'protein_id',\n",
    "        'accession_number',\n",
    "        None,\n",
    "        None,\n",
    "        'keyword'\n",
    "    ]\n",
    "    _id = None\n",
    "    _flag = '-'\n",
    "    for _line in _input:        \n",
    "        _line = _line.strip()\n",
    "        if _line.startswith('#'):\n",
    "            continue\n",
    "        _parts = _line.split()\n",
    "        if len(_parts) < 2:\n",
    "            continue\n",
    "        _field = _parts.pop(0)\n",
    "        if _field not in _fields :\n",
    "            continue\n",
    "        _data = [_id]\n",
    "        _lines = []\n",
    "        _file = None\n",
    "        if _line[-1] == '.':\n",
    "            _line = _line[:-1]\n",
    "        if _id == None or _field == _fields[0] and _convert(_parts[0]) != _id:\n",
    "            if _id:\n",
    "            # creating SQL INSERT INTO statements\n",
    "            for _line in _strings([_id, _flag], [_labels[0], '_flag'], 'uniprot', None):\n",
    "                os.write(_fact_file, _line)\n",
    "            _id = _convert(_parts[0]) \n",
    "            _flag = '-'\n",
    "        elif _field == _fields[1] or _field == _fields[4]:\n",
    "            _parts = _line.split(';')\n",
    "            _parts[0] = _parts[0][2:]\n",
    "            _parts[0] = _parts[0].strip()\n",
    "            _index = _fields.index(_field)\n",
    "            _label = _labels[_index]\n",
    "            for _part in _parts:\n",
    "                _part = _convert(_part)\n",
    "                if _part != '':\n",
    "                    # creating SQL INSERT INTO statements\n",
    "                    _lines = _strings([_id, _part], [_labels[0], _label], _label, None)\n",
    "        elif _field == _fields[5] and _parts.pop(0) == 'GO;':\n",
    "            _parts = _line.split(';')\n",
    "            _parts.pop(0)\n",
    "            _data = [_convert(_parts.pop(0)), _id]\n",
    "            # \n",
    "            for _line in _strings(_data, ['go_id', _labels[0]], 'go_uniprot', None):\n",
    "                os.write(_dimension_file, _line)\n",
    "            _data.pop()\n",
    "            _values = _parts.pop(0)\n",
    "            _values = _values.split(':')\n",
    "            _category = _values[0].strip()\n",
    "            if _category == 'P':\n",
    "                _data.append(_convert('Process'))\n",
    "            elif _category == 'F':\n",
    "                _data.append(_convert('Function'))\n",
    "            elif _category == 'C':\n",
    "                _data.append(_convert('Component'))\n",
    "            else:\n",
    "                assert False\n",
    "            # providing consistency to SQL INSERT INTO statements\n",
    "            _lines.append(_consistency(_data, ['go_id', 'category'], 'go'))\n",
    "            _data.pop()\n",
    "            _data.append(_convert(_values[1]))\n",
    "            # providing consistency to SQL INSERT INTO statements\n",
    "            _lines.append(_consistency(_data, ['go_id', 'go_term'], 'go_term'))        \n",
    "            _data.pop()\n",
    "            _values = _parts.pop(0)\n",
    "            _values = _values.split(':')\n",
    "            _data.append(_convert(_values[0]))\n",
    "            _data.append(_replace('-'))\n",
    "            _data.append(_convert(_values[1]))\n",
    "            # providing consistency to SQL INSERT INTO statements\n",
    "            _lines.append(_consistency(_data, ['go_id', 'evidence', 'qualifier', 'source'], 'evidence'))        \n",
    "            _file = _fact_file\n",
    "        elif _field == _fields[5] and _parts[0] in ['RecName:', 'AltName:']:\n",
    "            _parts = _line.split(':')\n",
    "            _values = _parts.pop(0)\n",
    "            _values = _values.split()\n",
    "            _data.append(_convert(_values[1]))\n",
    "            _values = _parts.pop(0)\n",
    "            _values = _values.split('=')\n",
    "            _data.append(_convert(_values[0]))\n",
    "            _data.append(_convert(_values[1][:-1]))\n",
    "        elif _field == _fields[5] and _parts.pop(0) == 'Flags:':\n",
    "            _flag = _parts[0];\n",
    "            _flag = _convert(_flag[:-1])\n",
    "        elif _field in _fields:\n",
    "            continue\n",
    "        if not _file: \n",
    "            _file = _dimension_file\n",
    "        # writing SQL statements\n",
    "        for _line in _lines:\n",
    "            os.write(_file, _line)\n",
    "    for _line in _strings([_id, _flag], [_labels[0], '_flag'], 'uniprot', None):\n",
    "        os.write(_fact_file, _line)\n",
    "    os.close(_fact_file)\n",
    "    # removing duplicate lines\n",
    "    _deduplicate(_datasets['UniProtKB'], _fact_path, _dimension_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import unitprot_parser as upp\n",
    "\n",
    "upp.processUnitProtData(_datasets['UniProtKB'], _datasets['UniProtKB'], True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to database\n",
    "def _connect(_configuration, _create = False):\n",
    "    _params = _configuration\n",
    "    print('Connecting to the database \\\"' + _configuration['database'] + '\\\" in PostgreSQL')\n",
    "    _connection = psycopg2.connect(**_params)\n",
    "    _connection.set_session(autocommit = True)\n",
    "    _cursor = _connection.cursor()\n",
    "    print('Version of PostgreSQL:')\n",
    "    _cursor.execute('SELECT version()')\n",
    "    _version = _cursor.fetchone()\n",
    "    print(_version)\n",
    "    _cursor.close()\n",
    "    # creating tables\n",
    "    if _create:\n",
    "        with _connection.cursor() as _cursor:\n",
    "            _cursor.execute(open('../database/database.sql', 'r').read())\n",
    "    return _connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating tables\n",
    "def _populate(_path, _connection):\n",
    "    with _connection.cursor() as _cursor:\n",
    "        _cursor.execute('SELECT current_database()')\n",
    "        _database = _cursor.fetchone()\n",
    "        print('Populating the database \\\"' + _database[0] + '\\\" using the file \\\"' + _path + '\\\"')\n",
    "        _cursor.execute(open(_path, 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_connection = _connect(_configuration, _create = True)\n",
    "\n",
    "_datasets = [\n",
    "    _datasets['Homo_sapiens.gene_info'],\n",
    "    _datasets['gene2go'],\n",
    "    _datasets['UniProtKB'],\n",
    "]\n",
    "\n",
    "# populating tables\n",
    "for _dataset in _datasets:\n",
    "    _populate(_dataset, _connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #\n",
    "'''    \n",
    "_configuration = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres'\n",
    "}\n",
    "\n",
    "_connection = _connect(_configuration, _create = False)\n",
    "\n",
    "_connection.cursor().execute('DROP DATABASE IF EXISTS \"bioinformatics\";')\n",
    "\n",
    "_connection.close()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
